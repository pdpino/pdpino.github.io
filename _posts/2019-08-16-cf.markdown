---
layout: post
title:  "Collaborative Filtering"
date:   2019-08-16 16:00:00 -0400
categories: week1
week: "1"
---

**Book chapter:** Schafer, J. B., Frankowski, D., Herlocker, J., & Sen, S. (2007). Collaborative filtering recommender systems.

This book chapter provides a big overview of the Collaborative Filtering (CF) Recommender Systems at the time.
The information is very thorough, as they show core concepts, uses, algorithms, evaluation techniques and the next challenges for the topic. I think it gives a good overview for someone starting to study this topic, though by now it may be a little outdated in some aspects.

I think it would be interesting to see an updated version of this, showing how the concepts presented have developed in the past years.
For example, they propose multiple criteria to evaluate a recommender system, and I would like to see what metrics or methods are currently used in some of those criteria (e.g. how is novelty being evaluated?), or how new criteria have emerged.
For instance, I recently heard of the _fairness_ criterion, that addresses the issue of which groups of users are favored by the system, if any, and which groups aren't.

Moreover, I thought of issues of trust and security that some recommender systems may exhibit now, that probably weren't observed back in 2007.
First, there is the polarization phenomenon observed in social networks, for instance, political polarization.
The user-based CF systems work like this by design: cluster the users in different groups, potentially opposite groups, and recommend them things that they like.
This seems harmless when recommending music or movies, but when Facebook or Twitter chooses what news or items to show you, the polarization may have more severe effects.
Second, and very related to the first issue, there is the fake news problem.
A recent example of all of this is the [Cambridge Analytica scandal][cambridge-scandal].
Also, a quick [google scholar search][google-scholar-search] shows a lot of recent articles about social media, polarization and fake news.

Though all of these issues may not be specific to CF systems, I think it's important that they are and continue being addressed by researchers.
Can the recommender systems be (maliciously) leveraged to distribute fake news?
Or to favor political campaigns?
Who is reliable for this?
Could the systems be designed to prevent or detect this kind of attacks?


[google-scholar-search]: https://scholar.google.cl/scholar?as_ylo=2018&q=social+media+polarization&hl=en&as_sdt=0,5&as_vis=1
[cambridge-scandal]: https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal
